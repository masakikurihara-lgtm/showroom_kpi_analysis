import streamlit as st
import pandas as pd
import numpy as np
import io
import requests
import json
from datetime import datetime, date, timedelta
import pytz
import plotly.graph_objects as go
import plotly.express as px
import time
from bs4 import BeautifulSoup


# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="SHOWROOM ãƒ©ã‚¤ãƒãƒ¼KPIåˆ†æãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.markdown(
    "<h1 style='font-size:28px; text-align:center; color:#1f2937;'>SHOWROOM ãƒ©ã‚¤ãƒãƒ¼KPIåˆ†æãƒ„ãƒ¼ãƒ«</h1>",
    unsafe_allow_html=True
)

# èª¬æ˜æ–‡
st.markdown(
    "<p style='font-size:16px; text-align:center; color:#4b5563;'>",
    unsafe_allow_html=True
)

st.markdown("---")


# --- é–¢æ•°å®šç¾© ---
@st.cache_data(ttl=60) # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿æŒã‚’60ç§’ã«å¤‰æ›´
def fetch_event_data():
    """ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’CSVã‹ã‚‰èª­ã¿è¾¼ã¿ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹"""
    try:
        event_url = "https://mksoul-pro.com/showroom/file/sr-event-entry.csv"
        event_df = pd.read_csv(event_url)
        event_df.columns = [col.strip() for col in event_df.columns]
        return event_df
    except Exception as e:
        st.error(f"ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()

# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†é–¢æ•°
# @st.cache_data(ttl=3600) # ãƒ‡ãƒ¼ã‚¿ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’1æ™‚é–“ä¿æŒ
def load_and_preprocess_data(account_id, start_date, end_date):
    if not account_id:
        st.error("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return None, None, None, None
    
    if start_date > end_date:
        st.error("é–‹å§‹æ—¥ã¯çµ‚äº†æ—¥ã‚ˆã‚Šå‰ã®æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return None, None, None, None

    loop_start_date = start_date.date() if isinstance(start_date, (datetime, pd.Timestamp)) else start_date
    loop_end_date = end_date.date() if isinstance(end_date, (datetime, pd.Timestamp)) else end_date

    mksp_dfs = []
    df_temp = pd.DataFrame()
    room_id_temp = None
    room_name_temp = None
    
    # èª­ã¿è¾¼ã¿å¯¾è±¡ã®æœˆã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
    target_months = []
    current_date_loop = loop_start_date
    while current_date_loop <= loop_end_date:
        target_months.append(current_date_loop)
        if current_date_loop.month == 12:
            current_date_loop = date(current_date_loop.year + 1, 1, 1)
        else:
            current_date_loop = date(current_date_loop.year, current_date_loop.month + 1, 1)
    
    total_months = len(target_months)

    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’ä¸€æœ¬ã§å®Ÿè£…
    progress_bar = st.progress(0)
    progress_text = st.empty()
    
    # å…¨ä½“ãƒ‡ãƒ¼ã‚¿(mksp)ã¨å€‹äººãƒ‡ãƒ¼ã‚¿ã‚’åˆ†ã‘ã‚‹
    is_mksp = account_id == "mksp"

    # å…¨ä½“ãƒ‡ãƒ¼ã‚¿(mksp)ã®èª­ã¿è¾¼ã¿
    for i, current_date in enumerate(target_months):
        year = current_date.year
        month = current_date.month
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®é€²æ—è¨ˆç®—
        # å€‹äººãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯2ã¤ã®ãƒ«ãƒ¼ãƒ—ãŒã‚ã‚‹ã®ã§ã€é€²æ—ã‚’åˆ†ã‘ã¦è¨ˆç®—
        if not is_mksp:
            progress = (i + 1) / (total_months * 2)
        else:
            progress = (i + 1) / total_months
        
        progress_bar.progress(progress)
        progress_text.text(f"ğŸ“Š å…¨ä½“ãƒ‡ãƒ¼ã‚¿ ({year}å¹´{month}æœˆ) ã‚’å–å¾—ä¸­... ({i+1}/{total_months})")

        url = f"https://mksoul-pro.com/showroom/csv/{year:04d}-{month:02d}_all_all.csv"
        
        try:
            response = requests.get(url)
            response.raise_for_status()
            csv_data = io.StringIO(response.content.decode('utf-8-sig'))
            df = pd.read_csv(csv_data, on_bad_lines='skip')
            df.columns = df.columns.str.strip().str.replace('"', '')
            mksp_dfs.append(df)
        
        except requests.exceptions.RequestException as e:
            if e.response and e.response.status_code == 404:
                # st.warning(f"âš ï¸ {year}å¹´{month}æœˆã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                pass
            else:
                st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                progress_bar.empty()
                progress_text.empty()
                return None, None, None, None
        except Exception as e:
            st.error(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
            progress_bar.empty()
            progress_text.empty()
            return None, None, None, None
            
    if not mksp_dfs:
        st.error(f"é¸æŠã•ã‚ŒãŸæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸€ã¤ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        progress_bar.empty()
        progress_text.empty()
        return None, None, None, None

    combined_mksp_df = pd.concat(mksp_dfs, ignore_index=True)
    if "é…ä¿¡æ—¥æ™‚" not in combined_mksp_df.columns:
        raise KeyError("CSVãƒ•ã‚¡ã‚¤ãƒ«ã« 'é…ä¿¡æ—¥æ™‚' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    combined_mksp_df["é…ä¿¡æ—¥æ™‚"] = pd.to_datetime(combined_mksp_df["é…ä¿¡æ—¥æ™‚"])

    mksp_df_temp = combined_mksp_df.copy()

    # å€‹åˆ¥ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã®èª­ã¿è¾¼ã¿ï¼ˆmkspã§ã¯ãªã„å ´åˆã®ã¿ï¼‰
    if not is_mksp:
        individual_dfs = []
        for i, current_date in enumerate(target_months):
            year = current_date.year
            month = current_date.month
            
            # å€‹äººãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æ™‚ã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¨ˆç®—
            progress = (total_months + i + 1) / (total_months * 2)
            
            progress_bar.progress(progress)
            progress_text.text(f"ğŸ‘¤ å€‹äººãƒ‡ãƒ¼ã‚¿ ({year}å¹´{month}æœˆ) ã‚’å–å¾—ä¸­... ({i+1}/{total_months})")
            
            url = f"https://mksoul-pro.com/showroom/csv/{year:04d}-{month:02d}_all_all.csv"
            
            try:
                response = requests.get(url)
                response.raise_for_status()
                csv_data = io.StringIO(response.content.decode('utf-8-sig'))
                df = pd.read_csv(csv_data, on_bad_lines='skip')
                df.columns = df.columns.str.strip().str.replace('"', '')
                individual_dfs.append(df)
            
            except requests.exceptions.RequestException as e:
                if e.response and e.response.status_code == 404:
                    # st.warning(f"âš ï¸ {year}å¹´{month}æœˆã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                    pass
                else:
                    st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    progress_bar.empty()
                    progress_text.empty()
                    return None, None, None, None
            except Exception as e:
                st.error(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
                progress_bar.empty()
                progress_text.empty()
                return None, None, None, None

        if not individual_dfs:
            st.warning(f"æŒ‡å®šã•ã‚ŒãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDï¼ˆ{account_id}ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ãŒé¸æŠã•ã‚ŒãŸæœŸé–“ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            progress_bar.empty()
            progress_text.empty()
            return None, None, None, None
            
        individual_combined_df = pd.concat(individual_dfs, ignore_index=True)
        if "é…ä¿¡æ—¥æ™‚" not in individual_combined_df.columns:
            raise KeyError("CSVãƒ•ã‚¡ã‚¤ãƒ«ã« 'é…ä¿¡æ—¥æ™‚' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        individual_combined_df["é…ä¿¡æ—¥æ™‚"] = pd.to_datetime(individual_combined_df["é…ä¿¡æ—¥æ™‚"])

        filtered_by_account_df = individual_combined_df[individual_combined_df["ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID"] == account_id].copy()
        
        if isinstance(start_date, (datetime, pd.Timestamp)):
            filtered_df = filtered_by_account_df[
                (filtered_by_account_df["é…ä¿¡æ—¥æ™‚"] >= start_date) & 
                (filtered_by_account_df["é…ä¿¡æ—¥æ™‚"] <= end_date)
            ].copy()
        else:
            filtered_df = filtered_by_account_df[
                (filtered_by_account_df["é…ä¿¡æ—¥æ™‚"].dt.date >= start_date) & 
                (filtered_by_account_df["é…ä¿¡æ—¥æ™‚"].dt.date <= end_date)
            ].copy()
        
        df_temp = filtered_df.copy()
        if "ãƒ«ãƒ¼ãƒ ID" in df_temp.columns and not df_temp.empty:
            room_id_temp = df_temp["ãƒ«ãƒ¼ãƒ ID"].iloc[0]
        if "ãƒ«ãƒ¼ãƒ å" in df_temp.columns and not df_temp.empty:
            room_name_temp = df_temp["ãƒ«ãƒ¼ãƒ å"].iloc[0]

    # mkspã®å ´åˆã¯ã€mksp_df_tempã‚’ãã®ã¾ã¾df_tempã¨ã—ã¦æ‰±ã†
    else:
        filtered_by_account_df = combined_mksp_df.copy()
        if isinstance(start_date, (datetime, pd.Timestamp)):
            filtered_df = filtered_by_account_df[
                (filtered_by_account_df["é…ä¿¡æ—¥æ™‚"] >= start_date) & 
                (filtered_by_account_df["é…ä¿¡æ—¥æ™‚"] <= end_date)
            ].copy()
        else:
            filtered_df = filtered_by_account_df[
                (filtered_by_account_df["é…ä¿¡æ—¥æ™‚"].dt.date >= start_date) & 
                (filtered_by_account_df["é…ä¿¡æ—¥æ™‚"].dt.date <= end_date)
            ].copy()
        
        df_temp = filtered_df.copy()
        room_id_temp = None
        room_name_temp = None

    # æ•°å€¤å‹ã«å¤‰æ›ã™ã‚‹å…±é€šå‡¦ç†
    def convert_to_numeric(df):
        if df is None or df.empty:
            return df
        numeric_cols = [
            "åˆè¨ˆè¦–è´æ•°", "è¦–è´ä¼šå“¡æ•°", "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°", "ç²å¾—æ”¯æ´point", "ã‚³ãƒ¡ãƒ³ãƒˆæ•°",
            "ã‚®ãƒ•ãƒˆæ•°", "æœŸé™ã‚ã‚Š/æœŸé™ãªã—SGç·é¡", "ã‚³ãƒ¡ãƒ³ãƒˆäººæ•°", "åˆã‚³ãƒ¡ãƒ³ãƒˆäººæ•°",
            "ã‚®ãƒ•ãƒˆäººæ•°", "åˆã‚®ãƒ•ãƒˆäººæ•°", "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¢—æ¸›æ•°", "åˆãƒ«ãƒ¼ãƒ æ¥è¨ªè€…æ•°", "é…ä¿¡æ™‚é–“(åˆ†)", "çŸ­æ™‚é–“æ»åœ¨è€…æ•°",
            "æœŸé™ã‚ã‚Š/æœŸé™ãªã—SGã®ã‚®ãƒ•ãƒ†ã‚£ãƒ³ã‚°æ•°", "æœŸé™ã‚ã‚Š/æœŸé™ãªã—SGã®ã‚®ãƒ•ãƒ†ã‚£ãƒ³ã‚°äººæ•°"
        ]
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(
                    df[col].astype(str).str.replace(",", "").replace("-", "0"),
                    errors='coerce'
                ).fillna(0)
        return df

    mksp_df_temp = convert_to_numeric(mksp_df_temp)
    df_temp = convert_to_numeric(df_temp)

    # æœ€çµ‚çš„ãªãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’éè¡¨ç¤ºã«ã™ã‚‹
    progress_bar.empty()
    progress_text.empty()
    
    return mksp_df_temp, df_temp, room_id_temp, room_name_temp

# ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ«ãƒ¼ãƒ IDã¨ãƒ«ãƒ¼ãƒ åã‚’å–å¾—ã™ã‚‹é–¢æ•°
@st.cache_data(ttl=3600)
def fetch_room_info(account_id):
    if not account_id:
        return None, None
    url = f"https://mksoul-pro.com/showroom/{account_id}"
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        room_id = None
        room_name = None
        
        # ãƒ«ãƒ¼ãƒ IDã‚’metaã‚¿ã‚°ã‹ã‚‰å–å¾—
        meta_og_url = soup.find('meta', property='og:url')
        if meta_og_url:
            og_url = meta_og_url['content']
            room_id = og_url.split('/')[-1]
            
        # ãƒ«ãƒ¼ãƒ åã‚’metaã‚¿ã‚°ã‹ã‚‰å–å¾—
        meta_og_title = soup.find('meta', property='og:title')
        if meta_og_title:
            room_name = meta_og_title['content'].replace("ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«", "")
            
        if not room_id or not room_name:
            st.warning(f"âš ï¸ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID '{account_id}' ã®ãƒ«ãƒ¼ãƒ æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return None, None
            
        return room_id, room_name
        
    except requests.exceptions.Timeout:
        st.error("âŒ ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return None, None
    except requests.exceptions.RequestException as e:
        st.error(f"âŒ ãƒ«ãƒ¼ãƒ æƒ…å ±ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None
    except Exception as e:
        st.error(f"âŒ ãƒ«ãƒ¼ãƒ æƒ…å ±ã®è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None
        
        
# KPIåˆ†æé–¢æ•°
def analyze_kpis(df):
    if df is None or df.empty:
        return {}
    
    analysis = {
        "å¹³å‡ç²å¾—æ”¯æ´point": df["ç²å¾—æ”¯æ´point"].mean(),
        "å¹³å‡ã‚³ãƒ¡ãƒ³ãƒˆæ•°": df["ã‚³ãƒ¡ãƒ³ãƒˆæ•°"].mean(),
        "å¹³å‡ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¢—æ¸›æ•°": df["ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¢—æ¸›æ•°"].mean(),
        "å¹³å‡åˆãƒ«ãƒ¼ãƒ æ¥è¨ªè€…æ•°": df["åˆãƒ«ãƒ¼ãƒ æ¥è¨ªè€…æ•°"].mean(),
        "å¹³å‡è¦–è´ä¼šå“¡æ•°": df["è¦–è´ä¼šå“¡æ•°"].mean(),
        "å¹³å‡é…ä¿¡æ™‚é–“(åˆ†)": df["é…ä¿¡æ™‚é–“(åˆ†)"].mean(),
        "ç·é…ä¿¡æ™‚é–“(æ™‚é–“)": df["é…ä¿¡æ™‚é–“(åˆ†)"].sum() / 60,
        "å¹³å‡ç²å¾—SGç·é¡": df["æœŸé™ã‚ã‚Š/æœŸé™ãªã—SGç·é¡"].mean()
    }
    return analysis

# --- Streamlit UI ---
st.markdown("### ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹è¨­å®š")

# ãƒ•ã‚©ãƒ¼ãƒ ã‚’ä½¿ç”¨ã—ã¦å…¥åŠ›æ¬„ã‚’ã¾ã¨ã‚ã‚‹
with st.form(key='analysis_form'):
    account_id = st.text_input(
        "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID", 
        placeholder="ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ä¾‹:mksp)",
        help="å€‹äººã®å ´åˆã¯ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã€å…¨ä½“ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ã€Œmkspã€ã¨å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    ).strip()

    st.markdown("---")
    
    col1, col2 = st.columns(2)
    with col1:
        start_date = st.date_input(
            "ğŸ“… é–‹å§‹æ—¥",
            min_value=date(2023, 1, 1),
            max_value=date.today(),
            value=date.today() - timedelta(days=30),
            help="åˆ†æã‚’é–‹å§‹ã™ã‚‹æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"
        )

    with col2:
        end_date = st.date_input(
            "ğŸ“… çµ‚äº†æ—¥",
            min_value=date(2023, 1, 1),
            max_value=date.today(),
            value=date.today(),
            help="åˆ†æã‚’çµ‚äº†ã™ã‚‹æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"
        )

    st.markdown("---")

    submit_button = st.form_submit_button(label='ğŸš€ åˆ†æé–‹å§‹')

if submit_button:
    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»å‰å‡¦ç†ä¸­..."):
        mksp_df, df, room_id, room_name = load_and_preprocess_data(account_id, start_date, end_date)

    if df is None or mksp_df is None or df.empty:
        st.warning("âš ï¸ å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã‚„æœŸé–“ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    st.success("âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    # å–å¾—ã—ãŸãƒ«ãƒ¼ãƒ æƒ…å ±ã‚’è¡¨ç¤º
    if room_name:
        st.markdown(f"### ğŸ‘¤ ãƒ«ãƒ¼ãƒ å: {room_name}")
    if room_id:
        st.markdown(f"### ğŸ†” ãƒ«ãƒ¼ãƒ ID: {room_id}")

    # KPIåˆ†æ
    st.markdown("---")
    st.markdown("### ğŸ“ˆ ä¸»è¦KPIã®ã‚µãƒãƒªãƒ¼")

    analysis_mksp = analyze_kpis(mksp_df)
    analysis_user = analyze_kpis(df)
    
    kpi_col1, kpi_col2, kpi_col3, kpi_col4 = st.columns(4)
    with kpi_col1:
        st.metric(
            label="åˆè¨ˆç²å¾—æ”¯æ´Point", 
            value=f"{df['ç²å¾—æ”¯æ´point'].sum():,.0f} pt",
            delta=f"{df['ç²å¾—æ”¯æ´point'].sum() - mksp_df['ç²å¾—æ”¯æ´point'].sum():,.0f} pt",
            delta_color="normal"
        )
    with kpi_col2:
        st.metric(
            label="åˆè¨ˆè¦–è´ä¼šå“¡æ•°",
            value=f"{df['è¦–è´ä¼šå“¡æ•°'].sum():,.0f} äºº",
            delta=f"{df['è¦–è´ä¼šå“¡æ•°'].sum() - mksp_df['è¦–è´ä¼šå“¡æ•°'].sum():,.0f} äºº",
            delta_color="normal"
        )
    with kpi_col3:
        st.metric(
            label="åˆè¨ˆã‚³ãƒ¡ãƒ³ãƒˆæ•°",
            value=f"{df['ã‚³ãƒ¡ãƒ³ãƒˆæ•°'].sum():,.0f} ã‚³ãƒ¡",
            delta=f"{df['ã‚³ãƒ¡ãƒ³ãƒˆæ•°'].sum() - mksp_df['ã‚³ãƒ¡ãƒ³ãƒˆæ•°'].sum():,.0f} ã‚³ãƒ¡",
            delta_color="normal"
        )
    with kpi_col4:
        st.metric(
            label="ç·é…ä¿¡æ™‚é–“",
            value=f"{df['é…ä¿¡æ™‚é–“(åˆ†)'].sum():,.0f} åˆ†",
            delta=f"{df['é…ä¿¡æ™‚é–“(åˆ†)'].sum() - mksp_df['é…ä¿¡æ™‚é–“(åˆ†)'].sum():,.0f} åˆ†",
            delta_color="normal"
        )

    # ã‚°ãƒ©ãƒ•è¡¨ç¤º
    st.markdown("---")
    st.markdown("### ğŸ“Š æœŸé–“åˆ¥KPIæ¨ç§»")
    
    st.line_chart(df.set_index("é…ä¿¡æ—¥æ™‚")["ç²å¾—æ”¯æ´point"])

    st.markdown("---")
    st.markdown("### ğŸ† æ³¨ç›®ã™ã¹ãé…ä¿¡")
    
    # æ³¨ç›®ã™ã¹ãé…ä¿¡ã‚’æŠ½å‡º
    df_sorted_by_points = df.sort_values(by="ç²å¾—æ”¯æ´point", ascending=False).head(5)
    
    for index, row in df_sorted_by_points.iterrows():
        st.markdown(
            f"**é…ä¿¡æ—¥æ™‚:** {row['é…ä¿¡æ—¥æ™‚'].strftime('%Y-%m-%d %H:%M')}, "
            f"**ç²å¾—æ”¯æ´point:** {row['ç²å¾—æ”¯æ´point']:,}pt, "
            f"**è¦–è´ä¼šå“¡æ•°:** {row['è¦–è´ä¼šå“¡æ•°']:,}äºº"
        )

    st.markdown("---")
    st.markdown("### ğŸ¯ æ”¹å–„ã™ã¹ãæŒ‡æ¨™")

    # å…¨ä½“ãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒã—ã¦å¹³å‡ã‚’ä¸‹å›ã‚‹æŒ‡æ¨™ã‚’ç‰¹å®š
    user_kpis = df.mean(numeric_only=True)
    mksp_kpis = mksp_df.mean(numeric_only=True)
    
    improvement_points = []
    
    kpi_map = {
        'ç²å¾—æ”¯æ´point': 'ç²å¾—æ”¯æ´ãƒã‚¤ãƒ³ãƒˆ',
        'è¦–è´ä¼šå“¡æ•°': 'è¦–è´ä¼šå“¡æ•°',
        'ã‚³ãƒ¡ãƒ³ãƒˆæ•°': 'ã‚³ãƒ¡ãƒ³ãƒˆæ•°'
    }

    for kpi, name in kpi_map.items():
        if kpi in user_kpis and kpi in mksp_kpis:
            if user_kpis[kpi] < mksp_kpis[kpi]:
                improvement_points.append(f"**{name}:** ã‚ãªãŸã®å¹³å‡å€¤ ({user_kpis[kpi]:,.0f}) ã¯ã€å…¨ä½“å¹³å‡ ({mksp_kpis[kpi]:,.0f}) ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™ã€‚")

    if improvement_points:
        for point in improvement_points:
            st.warning(f"âš ï¸ {point}")
    else:
        st.info("âœ… å…¨ä½“å¹³å‡ã‚’ä¸Šå›ã‚‹ç´ æ™´ã‚‰ã—ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§ã™ï¼")

    st.markdown("---")
    
    # å„é…ä¿¡ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°è¡¨ç¤ºï¼ˆå±•é–‹å¯èƒ½ï¼‰
    st.subheader("ğŸ“ é…ä¿¡ãƒ‡ãƒ¼ã‚¿è©³ç´°")
    st.dataframe(df)

    # ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
    event_df = fetch_event_data()
    if not event_df.empty:
        st.markdown("---")
        st.subheader("ğŸ‰ é–‹å‚¬ä¸­ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±")
        
        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’æ—¥æœ¬æ™‚é–“ã«è¨­å®š
        jst = pytz.timezone('Asia/Tokyo')
        
        # 'ã‚¤ãƒ™ãƒ³ãƒˆé–‹å§‹æ—¥'ã¨'ã‚¤ãƒ™ãƒ³ãƒˆçµ‚äº†æ—¥'ã‚’æ—¥æœ¬æ™‚é–“ã®datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        event_df['ã‚¤ãƒ™ãƒ³ãƒˆé–‹å§‹æ—¥'] = pd.to_datetime(event_df['ã‚¤ãƒ™ãƒ³ãƒˆé–‹å§‹æ—¥'], format='%Y/%m/%d %H:%M:%S').dt.tz_localize(jst)
        event_df['ã‚¤ãƒ™ãƒ³ãƒˆçµ‚äº†æ—¥'] = pd.to_datetime(event_df['ã‚¤ãƒ™ãƒ³ãƒˆçµ‚äº†æ—¥'], format='%Y/%m/%d %H:%M:%S').dt.tz_localize(jst)
        
        # ç¾åœ¨æ™‚åˆ»ã‚’æ—¥æœ¬æ™‚é–“ã§å–å¾—
        now = datetime.now(jst)
        
        # é–‹å‚¬ä¸­ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        active_events = event_df[(event_df['ã‚¤ãƒ™ãƒ³ãƒˆé–‹å§‹æ—¥'] <= now) & (event_df['ã‚¤ãƒ™ãƒ³ãƒˆçµ‚äº†æ—¥'] >= now)]
        
        if not active_events.empty:
            for index, row in active_events.iterrows():
                st.markdown(f"**ã‚¤ãƒ™ãƒ³ãƒˆå:** {row['ã‚¤ãƒ™ãƒ³ãƒˆå']}")
                st.markdown(f"**ã‚¤ãƒ™ãƒ³ãƒˆæœŸé–“:** {row['ã‚¤ãƒ™ãƒ³ãƒˆé–‹å§‹æ—¥'].strftime('%Y/%m/%d %H:%M')} ~ {row['ã‚¤ãƒ™ãƒ³ãƒˆçµ‚äº†æ—¥'].strftime('%Y/%m/%d %H:%M')}")
                st.markdown(f"**èª¬æ˜:** {row['ã‚¤ãƒ™ãƒ³ãƒˆæ¦‚è¦']}")
                
                # ã‚¤ãƒ™ãƒ³ãƒˆè©³ç´°ã¸ã®ãƒªãƒ³ã‚¯
                st.markdown(f"[ã‚¤ãƒ™ãƒ³ãƒˆè©³ç´°ãƒšãƒ¼ã‚¸]({row['ã‚¤ãƒ™ãƒ³ãƒˆURL']})")
                st.markdown("---")
        else:
            st.info("ç¾åœ¨ã€é–‹å‚¬ä¸­ã®ã‚¤ãƒ™ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    # ãƒ’ãƒƒãƒˆåˆ†ææ©Ÿèƒ½
    st.markdown("---")
    st.subheader("ğŸš€ é…ä¿¡ãƒ’ãƒƒãƒˆåˆ†æ")
    
    st.info("ä»¥ä¸‹ã®æŒ‡æ¨™ãŒå¹³å‡ã‚’å¤§ããä¸Šå›ã£ãŸé…ä¿¡ã‚’è‡ªå‹•ã§ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚")

    if not df.empty:
        # é–¾å€¤ã¨ãªã‚‹å¹³å‡å€¤ã‚’è¨ˆç®—
        avg_viewers = df["åˆè¨ˆè¦–è´æ•°"].mean()
        avg_support_points = df["ç²å¾—æ”¯æ´point"].mean()
        avg_comments = df["ã‚³ãƒ¡ãƒ³ãƒˆæ•°"].mean()
        avg_followers = df["ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¢—æ¸›æ•°"].mean()
        avg_commenters = df["ã‚³ãƒ¡ãƒ³ãƒˆäººæ•°"].mean()
        avg_gifters = df["ã‚®ãƒ•ãƒˆäººæ•°"].mean()
        avg_sg_total = df["æœŸé™ã‚ã‚Š/æœŸé™ãªã—SGç·é¡"].mean()
        avg_sg_gifters = df["æœŸé™ã‚ã‚Š/æœŸé™ãªã—SGã®ã‚®ãƒ•ãƒ†ã‚£ãƒ³ã‚°äººæ•°"].mean()
        
        hit_df = df.copy()
        hit_df["ãƒ’ãƒƒãƒˆé …ç›®"] = [[] for _ in range(len(hit_df))]
        
        for index, row in hit_df.iterrows():
            hit_items = []
            if pd.notna(row['åˆè¨ˆè¦–è´æ•°']) and row['åˆè¨ˆè¦–è´æ•°'] >= avg_viewers * 1.5: hit_items.append('åˆè¨ˆè¦–è´æ•°')
            if pd.notna(row['ã‚³ãƒ¡ãƒ³ãƒˆæ•°']) and row['ã‚³ãƒ¡ãƒ³ãƒˆæ•°'] >= avg_comments * 1.5: hit_items.append('ã‚³ãƒ¡ãƒ³ãƒˆæ•°')
            if pd.notna(row['ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¢—æ¸›æ•°']) and row['ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¢—æ¸›æ•°'] >= avg_followers * 1.5: hit_items.append('ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¢—æ¸›æ•°')
            if pd.notna(row['ã‚³ãƒ¡ãƒ³ãƒˆäººæ•°']) and row['ã‚³ãƒ¡ãƒ³ãƒˆäººæ•°'] >= avg_commenters * 1.5: hit_items.append('ã‚³ãƒ¡ãƒ³ãƒˆäººæ•°')
            if pd.notna(row['åˆãƒ«ãƒ¼ãƒ æ¥è¨ªè€…æ•°']) and row['è¦–è´ä¼šå“¡æ•°'] > 0 and (row['åˆãƒ«ãƒ¼ãƒ æ¥è¨ªè€…æ•°'] / row['è¦–è´ä¼šå“¡æ•°']) >= 0.15: hit_items.append('åˆè¦‹è¨ªå•è€…ç‡')
            if pd.notna(row['åˆã‚³ãƒ¡ãƒ³ãƒˆäººæ•°']) and row['ã‚³ãƒ¡ãƒ³ãƒˆäººæ•°'] > 0 and (row['åˆã‚³ãƒ¡ãƒ³ãƒˆäººæ•°'] / row['ã‚³ãƒ¡ãƒ³ãƒˆäººæ•°']) >= 0.10: hit_items.append('åˆã‚³ãƒ¡ãƒ³ãƒˆç‡')
            if pd.notna(row['åˆã‚®ãƒ•ãƒˆäººæ•°']) and row['ã‚®ãƒ•ãƒˆäººæ•°'] > 0 and (row['åˆã‚®ãƒ•ãƒˆäººæ•°'] / row['ã‚®ãƒ•ãƒˆäººæ•°']) >= 0.12: hit_items.append('åˆã‚®ãƒ•ãƒˆç‡')
            if pd.notna(row['çŸ­æ™‚é–“æ»åœ¨è€…æ•°']) and row['è¦–è´ä¼šå“¡æ•°'] > 0 and (row['çŸ­æ™‚é–“æ»åœ¨è€…æ•°'] / row['è¦–è´ä¼šå“¡æ•°']) <= 0.15: hit_items.append('çŸ­æ™‚é–“æ»åœ¨è€…ç‡')
            if pd.notna(row['ç²å¾—æ”¯æ´point']) and row['ç²å¾—æ”¯æ´point'] >= avg_support_points * 2.7: hit_items.append('ç²å¾—æ”¯æ´point')
            if pd.notna(row['æœŸé™ã‚ã‚Š/æœŸé™ãªã—SGç·é¡']) and row['æœŸé™ã‚ã‚Š/æœŸé™ãªã—SGç·é¡'] >= avg_sg_total * 2.7: hit_items.append('SGç·é¡')
            if pd.notna(row['æœŸé™ã‚ã‚Š/æœŸé™ãªã—SGã®ã‚®ãƒ•ãƒ†ã‚£ãƒ³ã‚°äººæ•°']) and row['æœŸé™ã‚ã‚Š/æœŸé™ãªã—SGã®ã‚®ãƒ•ãƒ†ã‚£ãƒ³ã‚°äººæ•°'] >= avg_sg_gifters * 2.2: hit_items.append('SGã‚®ãƒ•ãƒˆäººæ•°')
            if pd.notna(row['ã‚®ãƒ•ãƒˆäººæ•°']) and row['ã‚®ãƒ•ãƒˆäººæ•°'] >= avg_gifters * 2.2: hit_items.append('ã‚®ãƒ•ãƒˆäººæ•°')
            if pd.notna(row['é…ä¿¡æ™‚é–“(åˆ†)']) and row['é…ä¿¡æ™‚é–“(åˆ†)'] >= df["é…ä¿¡æ™‚é–“(åˆ†)"].mean() * 1.5: hit_items.append('é•·æ™‚é–“é…ä¿¡')

            hit_df.at[index, "ãƒ’ãƒƒãƒˆé …ç›®"] = hit_items

        hit_streams = hit_df[hit_df["ãƒ’ãƒƒãƒˆé …ç›®"].apply(lambda x: len(x) > 0)]
        
        if not hit_streams.empty:
            st.markdown("ä»¥ä¸‹ã®é…ä¿¡ã¯ã€ç‰¹å®šã®æŒ‡æ¨™ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¨˜éŒ²ã—ã¾ã—ãŸã€‚")
            
            for index, row in hit_streams.iterrows():
                with st.expander(f"**æ—¥æ™‚: {row['é…ä¿¡æ—¥æ™‚'].strftime('%Y-%m-%d %H:%M')}**"):
                    st.write("---")
                    st.markdown(f"**ç²å¾—æ”¯æ´point:** {row['ç²å¾—æ”¯æ´point']:,}pt")
                    st.markdown(f"**åˆè¨ˆè¦–è´æ•°:** {row['åˆè¨ˆè¦–è´æ•°']:,}äºº")
                    st.markdown(f"**ã‚³ãƒ¡ãƒ³ãƒˆæ•°:** {row['ã‚³ãƒ¡ãƒ³ãƒˆæ•°']:,}ã‚³ãƒ¡")
                    st.markdown(f"**ãƒ’ãƒƒãƒˆé …ç›®:** {', '.join(row['ãƒ’ãƒƒãƒˆé …ç›®'])}")
        else:
            st.info("è©²å½“ã™ã‚‹ãƒ’ãƒƒãƒˆé…ä¿¡ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.warning("åˆ†æã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
